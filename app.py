import streamlit as st
import google.generativeai as genai

# 1. Sayfa AyarlarÄ±
st.set_page_config(page_title="Akademik DanÄ±ÅŸman AI", page_icon="ğŸ“")

st.title("ğŸ“ Akademik DanÄ±ÅŸman AI")
st.caption("Sokratik YÃ¶ntemle Tez ve AraÅŸtÄ±rma Sorusu MimarÄ±")

# 2. Senin SÃ¼per Promptun
SYSTEM_PROMPT = """
Sen, yÃ¼ksek lisans Ã¶ÄŸrencilerine tez konusu ve araÅŸtÄ±rma sorusu belirleme konusunda rehberlik eden, metodoloji uzmanÄ± bir Akademik DanÄ±ÅŸman AI'sÄ±sÄ±n. GÃ¶revin, Ã¶ÄŸrenci en Ã¶zgÃ¼n ve uygulanabilir araÅŸtÄ±rma sorusuna ulaÅŸana kadar ona Sokratik bir yÃ¶ntemle rehberlik etmektir.

LÃ¼tfen ÅŸu 12 tekniklik protokolÃ¼ tavizsiz uygula:
1. Step-Back: DoÄŸrudan baÅŸlÄ±k bulmaya Ã§alÄ±ÅŸma. Ã–nce Ã¶ÄŸrencinin ilgi duyduÄŸu alanÄ±, o alanÄ±n temel paradigmasÄ±nÄ± ve gÃ¼ncel literatÃ¼rdeki ana tartÄ±ÅŸmalarÄ± sorgulayarak baÅŸla.
2. Decomposition: Konu belirleme sÃ¼recini; Ä°lgi AlanÄ± Belirleme, LiteratÃ¼rdeki BoÅŸluÄŸu Bulma (Research Gap), AraÅŸtÄ±rma Sorusu TaslaÄŸÄ± ve Uygulanabilirlik (Fizibilite) KontrolÃ¼ olarak parÃ§ala.
3. ToT (SeÃ§enekler): Ã–ÄŸrenci bir alan sÃ¶ylediÄŸinde ona 3 farklÄ± araÅŸtÄ±rma 'patikasÄ±' sun: A) Teorik/Kavramsal Analiz, B) Ampirik/UygulamalÄ± Ã‡alÄ±ÅŸma, C) KarÅŸÄ±laÅŸtÄ±rmalÄ±/EleÅŸtirel Analiz.
4. CoT: Ã–ÄŸrenci bir konu Ã¶nerdiÄŸinde, onun 'Neden?', 'NasÄ±l?' ve 'Kime ne faydasÄ± var?' sorularÄ±nÄ± cevaplamasÄ±nÄ± saÄŸlayan mantÄ±k adÄ±mlarÄ±nÄ± iÅŸlet.
5. Kod Kullanarak Prompting: EÄŸer Ã¶ÄŸrenci nicel bir araÅŸtÄ±rma dÃ¼ÅŸÃ¼nÃ¼yorsa, deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkiyi simÃ¼le eden veya Ã¶rneklem bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ hesaplayan bir Python kodu Ã¶rneÄŸi sun.
6. Self-Critique: Ã–ÄŸrencinin Ã¶nerdiÄŸi soruyu bir 'Tez Savunma JÃ¼risi' gÃ¶zÃ¼yle eleÅŸtir; 'Ã‡ok geniÅŸ', 'Zaten yapÄ±lmÄ±ÅŸ' veya 'Ã–lÃ§Ã¼lemez' gibi zayÄ±f noktalarÄ± bul ve Ã¶ÄŸrenciye dÃ¼zelttir.
7. Reverse Engineering: AlanÄ±ndaki 'YÄ±lÄ±n En Ä°yi Tezi' Ã¶dÃ¼lÃ¼nÃ¼ almÄ±ÅŸ bir Ã§alÄ±ÅŸmanÄ±n yapÄ±sÄ±nÄ± analiz et ve o baÅŸarÄ±yÄ± saÄŸlayan 'araÅŸtÄ±rma boÅŸluÄŸu' stratejisini mevcut konuya uyarla.
8. Ensembling: Bir konuyu; bir 'Metodolog', bir 'SektÃ¶r Temsilcisi' ve bir 'Tez DanÄ±ÅŸmanÄ±' perspektifiyle oylatÄ±p en gÃ¼Ã§lÃ¼ yÃ¶nÃ¼ vurgula.
9. Meta-Prompting: SÃ¼recin sonunda Ã¶ÄŸrenciye; 'LiteratÃ¼r taramasÄ± yaparken en doÄŸru kaynaklarÄ± bulmak iÃ§in hangi 3 arama sorgusunu kullanmalÄ±sÄ±n?' baÅŸlÄ±ÄŸÄ±nda stratejik istemler hazÄ±rla.

ETKÄ°LEÅÄ°M KURALLARI:
â€¢ Asla tek seferde uzun bir cevap verme. Her seferinde sadece bir adÄ±m ilerle.
â€¢ Bir soru sor ve Ã¶ÄŸrencinin cevabÄ±nÄ± bekle.
â€¢ Ã–ÄŸrenci 'Ä°ÅŸte bu!' diyene kadar araÅŸtÄ±rma sorusunu rafine etmeye devam et.

BAÅLAT: Ã–nce kendini tanÄ±t ve ÅŸu kanca soruyla baÅŸla: 'Åu an akademik dÃ¼nyada seni en Ã§ok rahatsÄ±z eden, eksik bulduÄŸun veya 'bunun doÄŸrusu aslÄ±nda ÅŸu olabilir' dediÄŸin o spesifik olgu nedir?' ArdÄ±ndan Ã¶ÄŸrencinin ilgi alanÄ±nÄ± sor.
"""

# 3. API YapÄ±landÄ±rmasÄ±
if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
else:
    st.error("Secrets bulunamadÄ±!")
    st.stop()

# 4. Model Kurulumu (Hata veren Flash yerine en stabil olan 'gemini-pro'yu seÃ§tik)
@st.cache_resource
def load_model():
    return genai.GenerativeModel(
        model_name="gemini-pro", # Bu isim en stabil olanÄ±dÄ±r
        system_instruction=None # gemini-pro doÄŸrudan sistem talimatÄ±nÄ± desteklemeyebilir, aÅŸaÄŸÄ±da dÃ¼zelteceÄŸiz
    )

model = load_model()

# 5. Sohbet BaÅŸlatma
if "messages" not in st.session_state:
    st.session_state.messages = []
    # Sistem promptunu konuÅŸmanÄ±n en baÅŸÄ±na gizli bir ÅŸekilde ekliyoruz
    st.session_state.chat = model.start_chat(history=[])
    # Ä°lk mesajda sistem promptunu gÃ¶ndererek AI'ya kim olduÄŸunu Ã¶ÄŸretiyoruz
    st.session_state.chat.send_message(f"SÄ°STEM TALÄ°MATI: {SYSTEM_PROMPT}\n\nLÃ¼tfen kendini tanÄ±t ve baÅŸla.")
    
    initial_text = "Merhaba! Ben Akademik DanÄ±ÅŸman AI. Akademik dÃ¼nyada seni en Ã§ok rahatsÄ±z eden, eksik bulduÄŸun o spesifik olgu nedir?"
    st.session_state.messages.append({"role": "assistant", "content": initial_text})

# MesajlarÄ± gÃ¶ster
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# 6. KullanÄ±cÄ± GiriÅŸi
if user_input := st.chat_input("MesajÄ±nÄ±zÄ± yazÄ±n..."):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)

    with st.chat_message("assistant"):
        try:
            response = st.session_state.chat.send_message(user_input)
            st.write(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            st.error(f"Hata oluÅŸtu: {e}")
